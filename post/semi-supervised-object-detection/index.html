<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍 - kinredon's blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="kinredon"><meta name=description content="近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。 什么是半监督目标"><meta name=keywords content="blog,computer vision,deep learning"><meta name=generator content="Hugo 0.101.0"><link rel=canonical href=https://kinredon.github.io/post/semi-supervised-object-detection/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍"><meta property="og:description" content="近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。 什么是半监督目标"><meta property="og:type" content="article"><meta property="og:url" content="https://kinredon.github.io/post/semi-supervised-object-detection/"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-10-03T00:00:00+00:00"><meta property="article:modified_time" content="2021-10-04T16:11:41+08:00"><meta itemprop=name content="半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍"><meta itemprop=description content="近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。 什么是半监督目标"><meta itemprop=datePublished content="2021-10-03T00:00:00+00:00"><meta itemprop=dateModified content="2021-10-04T16:11:41+08:00"><meta itemprop=wordCount content="3243"><meta itemprop=keywords content="Semi-supervised Learning,Object Detection,Computer Vision,"><meta name=twitter:card content="summary"><meta name=twitter:title content="半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍"><meta name=twitter:description content="近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。 什么是半监督目标"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>kinredon</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://kinredon.github.io/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://kinredon.github.io/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://kinredon.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://kinredon.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://kinredon.github.io/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>kinredon</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://kinredon.github.io/>Home</a></li><li class=menu-item><a class=menu-item-link href=https://kinredon.github.io/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://kinredon.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://kinredon.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=https://kinredon.github.io/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍</h1><div class=post-meta><time datetime=2021-10-03 class=post-time>2021-10-03</time><div class=post-category><a href=https://kinredon.github.io/categories/computer-vision/>Computer Vision</a></div><span class=more-meta>约 3243 字</span>
<span class=more-meta>预计阅读 7 分钟</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#什么是半监督目标检测>什么是半监督目标检测？</a></li><li><a href=#consistency-based-semi-supervised-learning-for-object-detection-neurips-19>Consistency-based Semi-supervised Learning for Object Detection, NeurIPS 19</a></li><li><a href=#a-simple-semi-supervised-learning-framework-for-object-detection>A Simple Semi-Supervised Learning Framework for Object Detection</a></li><li><a href=#instant-teaching-an-end-to-end-semi-supervised-object-detection-framework>Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</a></li><li><a href=#data-uncertainty-guided-multi-phase-learning-for-semi-supervised-object-detection>Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection</a></li><li><a href=#unbiased-teacher-for-semi-supervised-object-detection>Unbiased Teacher for Semi-Supervised Object Detection</a></li><li><a href=#interactive-self-training-with-mean-teachers-for-semi-supervised-object-detection>Interactive Self-Training with Mean Teachers for Semi-supervised Object Detection</a></li><li><a href=#总结>总结</a></li></ul></nav></div></div><div class=post-content><p>近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。</p><h2 id=什么是半监督目标检测>什么是半监督目标检测？</h2><p>传统机器学习根据训练数据集中的标注情况，有着不同的场景，主要包括：监督学习、弱监督学习、弱半监督学习、半监督学习。由于目标检测任务的特殊性，在介绍半监督目标检测方法之前，我们查看一下目标检测在这四个方向下的具体设定，如下图所示（不包括无监督学习）：</p><link rel=stylesheet href=/css/hugo-easy-gallery.css><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205549.png alt="Figure 1: 图一 目标检测的不同的 setting"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205549.png itemprop=contentUrl></a><figcaption><p>Figure 1: 图一 目标检测的不同的 setting</p></figcaption></figure></div><p>总而言之，我们可以讲目标检测的 setting 分为四个部分：</p><ul><li><strong>有监督目标检测</strong> ：拥有大规模带标签的数据，包括完整的实例级别的标注，即包含坐标和类别信息；</li><li><strong>弱监督目标检测</strong> ：数据集中的标注仅包含类别信息，不包含坐标信息，如图一 b 所示；</li><li><strong>弱半监督目标检测</strong> ：数据集中拥有部分实例级别的标注，大量弱标注数据，模型希望利用大规模的弱标注数据提升模型的检测能力；</li><li><strong>半监督目标检测</strong> ：数据集中拥有部分实例级别的标注，大量未标注数据，模型希望利用大规模的无标注的数据提升模型的检测能力；</li></ul><p>半监督目标检测方法的核心在于，如何充分利用大量未标注、多样性的数据提升模型在测试集上的性能，目前的半监督目标检测方法主要有两个方向：</p><ol><li>一致性学习（Consistency based Learning）</li><li>伪标签（Pseudo-label based Learning）</li></ol><p>前者利用两个深度卷积神经网络学习同一张 unlabeled 图像不同扰动（比如水平翻转，不同的对比度，亮度等）之间的一致性，充分利用 unlabeled data的信息。后者利用在 labeled data 上学习的预训练模型对 unlabeled data 进行推理，经过 NMS 后减少大量冗余框后，利用一个阈值去挑选伪标签，最后利用伪标签训练模型。个人认为这两种方法没有本质的区别，本身都是伪标签技术，一致性学习可以认为是一种 soft pseudo label，而后者是一种 hard pseudo label。</p><p>接下来我讲介绍几篇近期半监督目标检测文章，主要发表在 ICLR, NeurIPS, CVPR等会议。</p><h2 id=consistency-based-semi-supervised-learning-for-object-detection-neurips-19>Consistency-based Semi-supervised Learning for Object Detection, NeurIPS 19</h2><p>CSD 这篇文章是比较早期的半监督目标检测方法，非常简单，该文章提出了一个 Consistency-based 半监督目标检测算法，可以同时在单阶段和双阶段检测器上工作。</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205728.png alt="Figure 2: 图二 CSD 半监督目标检测算法结构图"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205728.png itemprop=contentUrl></a><figcaption><p>Figure 2: 图二 CSD 半监督目标检测算法结构图</p></figcaption></figure></div><p>CSD 的结构如图二所示，以单阶段目标检测器为例，训练的损失函数主要包括两个部分，labeled sample 的监督损失和 unlabeled samples 的 Consistency loss。针对 unlabeled samples，首先将图像水平翻转，然后分别送入网络当中，得到对应的 Feature map，由于两张翻转的图像的空间位置是可以一一对应的，因此可以在对应的位置计算一致性损失。分类部分，利用 JS 散度作为 consistency loss；定位部分，利用 L2 loss 作为 consistency loss。</p><p>双阶段检测器的部分与单阶段检测器类似，差别主要在于 RPN（Region Proposal Network） 对于不同的输入可能产生不同的 proposals，因此在计算 consistency loss 时无法一一对应。解决此问题也很简单，两张图像使用同一个 RPN 生成同一组 RoI (Region of Interest) 来提取特征得到 proposals。</p><p>作者还提出了一个 Background elimination 方法来消除大量背景部分的损失主导训练过程的问题，因此作者定义了一个 mask 来过滤大量的背景样本：
\[
m^{k}=\left\{\begin{array}{ll}1, & \text { if } \operatorname{argmax}\left(f_{c l s}^{k}(I)\right) \neq b a c k g r o u n d \ 0, & \text { otherwise }\end{array}\right.
\]
其中，当该实例的类别不等于背景类时等于1，否则为 0。</p><h2 id=a-simple-semi-supervised-learning-framework-for-object-detection>A Simple Semi-Supervised Learning Framework for Object Detection</h2><p>STAC 提出了一个基于 hard pseudo label 的半监督目标检测算法，如图三所示，该方法包含四个步骤：</p><ol><li>首先利用 labeled data 训练一个 Teacher 模型；</li><li>生成 pseudo label, 将 unlabeled data 输入进 Teacher 网络中，得到大量的目标框预测结果，利用 NMS 消除大量的冗余框，最后使用阈值来挑选高置信度的 pseudo label；</li><li>应用 strong data augmentation。得到 pseudo label 后与 unlabeled image 图像相结合，包括图像级别的颜色抖动、geometric transformation(平移、旋转、剪切)、box-level transformation（小幅度的平移、旋转、剪切）；</li><li>计算无监督 loss （pseudo label）和监督学习 loss；</li></ol><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205743.png alt="Figure 3: 图三 STAC 半监督目标检测算法示意图"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205743.png itemprop=contentUrl></a><figcaption><p>Figure 3: 图三 STAC 半监督目标检测算法示意图</p></figcaption></figure></div><h2 id=instant-teaching-an-end-to-end-semi-supervised-object-detection-framework>Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</h2><p>Instant-Teaching 主要的 motivation 在于 STAC 仅生成一次的 pseudo label，即离线生成，在训练的过程中不会更新。这样的模式存在一个问题是，当训练的模型精度逐步提升，超过原本的模型，继续使用原来模型生成的 pseudo label 会限制模型精度进一步提升。因此作者提出 Instant-Teaching，以及 Instant-Teaching*。</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205807.png alt="Figure 4: 图四 Instant-Teaching 和 Instant-Teaching\* 示意图"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205807.png itemprop=contentUrl></a><figcaption><p>Figure 4: 图四 Instant-Teaching 和 Instant-Teaching\* 示意图</p></figcaption></figure></div><p>Instant-Teaching 采用即时生成 pseudo label 的模式，在每一个迭代中，包括两个步骤：</p><ol><li>生成 pseudo label: 对 unlabeled image 进行 weak augmentation，送入模型中得到 hard label；</li><li>利用生成的 pseudo label 进行 strong augmentation，除了 在 STAC 中的数据增强，还包括了 Mixup 和 Mosaic，利用增强后的数据训练模型；</li></ol><p>Instant-Teaching 主要提出了一个 co-rectify scheme 来解决 pseudo label 的 confirmation bias 的问题（噪声 pseudo label 的错误累计效应）。因此，作者利用两个模型，给予不同的初始化参数，输入不同的数据增强的样本，分别彼此纠正和检测对方生成的 pseudo label，形式如图四右半部分。</p><h2 id=data-uncertainty-guided-multi-phase-learning-for-semi-supervised-object-detection>Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection</h2><p>这篇工作提出一个多阶段的学习半监督目标检测学习算法,前面的方法基本在伪标签生成后，直接拟合生成的伪标签，这样将会引发 label noise overfitting 问题，即由于深度网络较强的拟合能力，即时错误的标签模型也能够拟合。因此作者利用图像级别 uncertainty 来进行多阶段学习，思想类似于课程学习（curriculum learning），先学习 easy 样本再学习 difficult data。具体来说，作者利用 RPN 出来的 proposal 的平均分数作为 uncertainty 的指标。平均分数越高，uncertainty 越小，视为 easy sample，反之为 difficult sample。</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205821.png alt="Figure 5: 图五 DUGMPL示意图"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205821.png itemprop=contentUrl></a><figcaption><p>Figure 5: 图五 DUGMPL示意图</p></figcaption></figure></div><p>在区域级别，作者提出 RoI 的 re-weighting 操作，作者从 Soft sampling for robust object detection 得到启示，对于具有噪声的数据（伪标签），在训练时，不同的 RoI 应该给予不同的权重，作者提出了几个的简单但有效的策略来解决这个问题，受限于篇幅，这里不再具体介绍，感兴趣可以去阅读原文的 Section 3.3.2.</p><h2 id=unbiased-teacher-for-semi-supervised-object-detection>Unbiased Teacher for Semi-Supervised Object Detection</h2><p>这篇文章发表在 ICLR 2021， 主要思想还是说现在的半监督目标检测算法生成的标签具有 bias，这里作者主要 argue 的点在于目标检测中存在天然的类别不平衡问题，包括 RPN 前景和背景的分类，ROIHead 的多类别分类，因此作者提出了一个 Unbiased Teacher 方法，来解决此问题。</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205832.png alt="Figure 6: 图六 Unbiased Teacher 示意图"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205832.png itemprop=contentUrl></a><figcaption><p>Figure 6: 图六 Unbiased Teacher 示意图</p></figcaption></figure></div><p>从方法上来说，非常的简单，首先是 Burn-IN stage，即在 labeled data 上训练一个预训练模型，然后利用 Mean Teacher 的结构，Teacher 生成 Pseudo label 来同时监督 RPN 和 ROIHead。不同的点在于，作者只利用 pseudo label 更新 RPN 和 ROIHead 的 classification 分支，主要原因在于由 confidence score 生成的 pseudo label 与 bounding box 位置的质量关系不大。除此之外，作者将原本的 cross entropy loss 替换为 Focal loss 来解决 pseudo label bias 问题，即 class imbalance。</p><h2 id=interactive-self-training-with-mean-teachers-for-semi-supervised-object-detection>Interactive Self-Training with Mean Teachers for Semi-supervised Object Detection</h2><p>这篇文章揭示了之前利用 pseudo label 的方法忽略了*同一张图片在不同的迭代的检测结果之间的差异性*，而且不同的模型对同一张图像的检测结果也有差异。</p><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205846.png alt="Figure 7: 图七 不同迭代的模型对同一张图像的预测结果(a)(b),不同 ROIHead 的检测结果"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205846.png itemprop=contentUrl></a><figcaption><p>Figure 7: 图七 不同迭代的模型对同一张图像的预测结果(a)(b),不同 ROIHead 的检测结果</p></figcaption></figure></div><p>因此作者提出一个基于 Mean Teacher 的 Interactive form of self-training 的半监督目标检测算法：</p><ol><li>解决不同训练迭代检测结果的不稳定问题，作者使用 NMS 将不同迭代的检测结果进行融合。</li><li>同时利用两个检测头部 ROIHead 生成 pseudo label，两个检测头部可以相互提供有用的互补信息。</li></ol><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205855.png alt="Figure 8: 图八 Interactive Self-Training 的算法步骤"></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205855.png itemprop=contentUrl></a><figcaption><p>Figure 8: 图八 Interactive Self-Training 的算法步骤</p></figcaption></figure></div><p>IST 算法的主要步骤如图八所示：</p><ul><li>使用 labeled data 训练一个拥有两个 ROIHead 的预训练模型;</li><li>利用预训练模型生成两个对应的伪标签;</li><li>利用 labeled data 和 unlabeled data 进行监督学习，图八中 Pseudo Labels Memory 用来使用 NMS 融合不同迭代的检测结果。该步骤详情如图九所示，利用 Mean Teacher 的结构，teacher 生成 pseudo label 并与 Memory 中的 pseudo label 进行融合，并更新 Memory。作者使用 Dropblock 模块确保不同的 ROIHead 能够独立收敛，并提供互补的信息，即图九中的 D。</li></ul><div class=box><figure itemprop=associatedMedia itemscope itemtype=http://schema.org/ImageObject><div class=img><img itemprop=thumbnail src=/ox-hugo/pngpaste_clipboard_file_20211003205905.png alt="Figure 9: 图九 Illustration of interactive self-training with mean teachers."></div><a href=/ox-hugo/pngpaste_clipboard_file_20211003205905.png itemprop=contentUrl></a><figcaption><p>Figure 9: 图九 Illustration of interactive self-training with mean teachers.</p></figcaption></figure></div><h2 id=总结>总结</h2><p>本文介绍了一些半监督目标检测算法，即如何利用大量的 unlabeled data 提升模型的检测性能，当前主要的方法包含 consistency based 以及 pseudo label based 两类。consistency based 方法主要学习模型在 unlabeled data 上的一致性，pseudo label 则利用在 unlabeled data 上生成 pseudo label 进而监督模型训练，主要的方向即为如何生成高质量的伪标签以及模型如何对抗在 unlabeled data 上的 noise label。本文介绍了的半监督目标检测方法不多，关于方法的介绍较为笼统，如有谬误，烦请指正，其中细节，还需仔细阅读文章，欢迎讨论。</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>kinredon</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2021-10-04</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://kinredon.github.io/tags/semi-supervised-learning/>Semi-supervised Learning</a>
<a href=https://kinredon.github.io/tags/object-detection/>Object Detection</a>
<a href=https://kinredon.github.io/tags/computer-vision/>Computer Vision</a></div><nav class=post-nav><a class=prev href=/post/how-to-publish-personal-website-on-github/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上</span>
<span class="prev-text nav-mobile">上一篇</span></a></nav></footer></article><div class="post bg-white"><script src=https://utteranc.es/client.js repo=kinredon/comments-blog issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:kinredon@163.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg></a><a href=https://github.com/kinredon rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://kinredon.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021 -
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>kinredon</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css integrity=sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js integrity=sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{})})</script><script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>