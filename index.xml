<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kinredon's blog</title><link>https://kinredon.github.io/</link><description>Recent content on kinredon's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 01 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://kinredon.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>About</title><link>https://kinredon.github.io/about/</link><pubDate>Sun, 20 Aug 2017 21:38:52 +0800</pubDate><guid>https://kinredon.github.io/about/</guid><description>&lt;p>Hugo is a static site engine written in Go.&lt;/p>
&lt;p>It makes use of a variety of open source projects including:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/spf13/cobra">Cobra&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/viper">Viper&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/jWalterWeatherman">J Walter Weatherman&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/spf13/cast">Cast&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Learn more and contribute on &lt;a href="https://github.com/gohugoio">GitHub&lt;/a>.&lt;/p></description></item><item><title>我的 2021 年总结</title><link>https://kinredon.github.io/post/2021_conclusion/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/2021_conclusion/</guid><description>&lt;p>转眼 2021 年过去了。整个 2021 有很多的收获，也有一些遗憾，今天是 2022 年的第一天，不免俗地想对 2021 做个总结，顺便给 2022 打打鸡血，立立 flag。&lt;/p>
&lt;h2 id="科研与学习">科研与学习&lt;/h2>
&lt;p>我目前主要的研究方向是在计算机视觉和迁移学习，2021 年一共发表了三篇文章，一篇一作 CVPR，一篇二作 ICCV，一篇三作 AAAI。CVPR 这篇比较坎坷，被拒稿过两次，横跨 CVPR2020 和 ECCV2020，曾经一度想要放弃，已经数不清 struggle 了多少个深夜，也记不清被导师说了多少次，最终在原有基础上再加了一些新东西，幸运地才得以发表，也凭借这篇文章成功念上了博士，算是苦尽甘来，但毕业的压力也接踵而至。ICCV 和 AAAI 是和实验室同学合作的文章，这两篇工作比较幸运，reviewer 给的评价都还不错，结果也和期望的差不多。&lt;/p>
&lt;p>经过这三次投稿经历，差不多掌握了一些基本的学术技巧，对整个流程也算比较了解，写 paper 完成了从导师说【英语很烂】到【还行】的艰难过渡。不过我自己感觉目前只能算把东西很朴素地表达清楚，仍有很大的进步空间。&lt;/p>
&lt;p>前面是收获，接下来便满是遗憾，今年前后做了两个课题，第一个课题已经失败，第二个课题没能赶上 CVPR 的 ddl，目前看来也差不多难产了，performance 和 novelty 都没有达到想要的效果，想想整个博士生涯也没几次 CVPR 的机会，就在自己手上断送了一个。接下来也要好好考虑是果断继续现在的课题，还是开新坑，放弃不甘心，沉没成本太高了，不放弃又怕陷入太深，好纠结：（&lt;/p>
&lt;p>从 10 月份开始，分享欲又上来了，于是在知乎上写了一些文章：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/404160115">半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/417259090">如何利用 org mode 写博客&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/417259374">使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/420796082">参加 VALSE 2021 的几点总结&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/449783484">Vision Transformer 在目标检测上的探索，DETR 系列文章解读（一）&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/450121658">Vision Transformer 在目标检测上的探索，DETR 系列文章解读（二）Deformable DETR&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>之前想过很多次现在的时刻，想到了很多感悟和槽点，没有记录下来，到了现在，一时却想不起来，以后还是应该多做记录。&lt;/p>
&lt;h2 id="生活">生活&lt;/h2>
&lt;p>2021 元旦从不在节假日出行的我，和初中同学傻傻地去了西岭雪山，真可谓人山人海，上山俩小时，下山三小时，不过风景还是很不错的。&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/IMG_5972_20220101223441.jpg" alt="Figure 1: 西岭雪山"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/IMG_5972_20220101223441.jpg" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 1: 西岭雪山&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/IMG_3580_20220101223400.jpg" alt="Figure 2: 西岭雪山"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/IMG_3580_20220101223400.jpg" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 2: 西岭雪山&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/IMG_3584_20220101223408.jpg" alt="Figure 3: 西岭雪山"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/IMG_3584_20220101223408.jpg" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 3: 西岭雪山&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>跟着学长的毕业旅行，去了一趟西藏，看了一些不一样的风景，虽然有些高反（以后可能都不会去海拔高于 3500m 的地方），但仍然很开心：）&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/FullSizeRender_20220101223854.jpg" alt="Figure 4: 布达拉宫"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/FullSizeRender_20220101223854.jpg" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 4: 布达拉宫&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>实验室项目原因，去了一趟北京支援小伙伴，遗憾没有时间游玩，每天都在所里打工，晚上回酒店不想出门 orz；&lt;/p>
&lt;p>去上海参加了 IJCAI-SAIA YES，听了很多场报告，可惜方向离得有些远，收获没想象的多，不过去交大见到了一多年未见的老同学，也算不虚此行；&lt;/p>
&lt;p>10月去杭州参加了 VALSE 2021,学术上的总结可以参考之前的文章 &lt;a href="https://zhuanlan.zhihu.com/p/420796082">参加 VALSE 2021 的几点总结&lt;/a>。杭州不愧是苏轼笔下的【欲把西湖比西子，浓妆淡抹总相宜】，在西湖逛了一下感觉真的很惬意，国内幸福感 top 的城市，气候适宜，风景宜人。在杭州也见到了刚毕业的师兄，原以为再次见面要很久以后了，没想到再次见面这么快。&lt;/p>
&lt;p>今年终于把困扰自己很久的牙齿给解决了，去补了牙，也把四颗心头大患的智齿拔除。&lt;/p>
&lt;p>2021 开始接触理财，看了一两本理财的书籍，瞬间以为自己成了理财大师，纵横股市，穿越牛熊。于是 2021 年重仓了白酒和医药，一年过去了，还是绿的orz，涨的时候一天涨零点几，跌的时候一天跌几个点，韭菜就要有韭菜的觉悟。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20220101230708.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20220101230708.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>年中的时候和女友确定关系，到现在也半年了，过得很开心，好喜欢和她在一起啊，想吹风想自由，_______；在一起后，我的生活也健康了很多，每天都能早起去吃早饭了，hhhh，感觉没有她后生活质量瞬间下降，比如昨天她回家了，今早就没起来（尴尬，罪过）。&lt;/p>
&lt;h2 id="2022-的一些-flag">2022 的一些 flag&lt;/h2>
&lt;p>对我而言，目前就应该做好手里的科研，毕竟人生没有这么一段时光可以让自己专研一门学问，内心深处还是希望能做成一些事情的。&lt;/p>
&lt;p>2022 立几个 flag：&lt;/p>
&lt;ol>
&lt;li>做两篇自己满意的工作；&lt;/li>
&lt;li>看一本正经学术写作的书，学习论文写作的技巧；&lt;/li>
&lt;li>每周总结写一篇文章或回答；&lt;/li>
&lt;li>持续不断地学习，除了科研之外，掌握一门新的实用技能；&lt;/li>
&lt;li>etc.&lt;/li>
&lt;/ol>
&lt;p>写到这里，都是一些碎碎念，脑子还有很多很多想法，但都虚无缥缈，2022 希望能够将它们具像化。最后【遇到再大的困难，加油，奥利给！】【只要思想不滑坡，方法总比困难多】&lt;/p>
&lt;p>2022&lt;/p>
&lt;p>It is about time.&lt;/p>
&lt;p>It is all about time.&lt;/p></description></item><item><title>Vision Transformer 在目标检测上的探索，DETR 系列文章解读（一）</title><link>https://kinredon.github.io/post/vision-transformer-for-object-detection/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/vision-transformer-for-object-detection/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>DETR（Detection Transformer） 将 CNN 与 Transformer 相结合，把检测任务当做集合预测 （set prediction） 任务，实现真正的 end-to-end 目标检测模型，即不需要任何的后处理阶段，比如 NMS 去除冗余框，直接从图片的原始像素得到最终的目标框和坐标预测。DETR 是 2020 年 5 月的文章，是早于 ViT （2020年10月），可以说 DETR 是 Vision Transformer 的奠基作品之一，不仅改变了大家对目标检测的一些固有看法，而且给后续 Vision Transformer 的发展具有重要意义，目前的引用量也有 1200+ （21 年 12 月）。&lt;/p>
&lt;h2 id="正文">正文&lt;/h2>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216110906.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216110906.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>如上图所示，DETR 整个结构非常简单，主要包括一个 CNN 模块用于从图像中提取特征和一个 Transformer encoder-decoder 模块直接产生一系列的目标框预测，图中的二分图匹配（bipartite matching）loss便是不会产生冗余框预测从而去除 NMS 的关键。具体来说，给定一张图片，通过 CNN 提取特征，将特征拉平作为序列输入到 transformer 中，然后直接预测 N 个目标框，每一个预测的目标框将与 ground truth 进行一对一的最优匹配，没有匹配上的预测框将被赋为空，即为图中的 no object，其实就是背景类。&lt;/p>
&lt;p>通过前面对整个架构的了解，可以看出 DETR 主要有两个关键的部分：&lt;/p>
&lt;ol>
&lt;li>二分图匹配 bipartite matching loss 的设计&lt;/li>
&lt;li>DETR 模型结构&lt;/li>
&lt;/ol>
&lt;p>接下来对这两部分进行详细的介绍。&lt;/p>
&lt;h3 id="二分图匹配-bipartite-matching-loss-的设计">二分图匹配 bipartite matching loss 的设计&lt;/h3>
&lt;p>bipartite matching loss 的核心就是做匹配，把预测的结果和 ground truth 做一一匹配。假设有 N 个预测，每个预测包含坐标框和类别概率，ground truth 也是有 N 个元素的集合（通常 ground truth 目标框的个数少于预测的目标框，剩余的部分用 no object 填充）。为了找到最优匹配，通过搜索预测结果中 N 元素的最优排列，使得两个集合对应元素有最小的 cost:&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160728.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160728.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>即找到 N 个预测结果与 ground truth 一一对应的匹配损失，得到 ground truth 每一个元素对应预测结果最小代价的 index。这样的匹配算法其实就是匈牙利匹配，Hungarian algorithm, 很多代码库都有相应的实现，直接可以利用。这里的 \(\mathcal{L}_{match}\) 包含了预测分类分数和定位两个指标，如下：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160754.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160754.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>有了最优的匹配之后，便可以计算损失函数，主要包括两个部分，一个是类别预测的 negative log-likehood，另一个是 bounding box 的回归损失：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160818.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160818.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>这里的回归损失函数包含两个损失，即 GIoU 损失和 L1 的损失：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160841.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225160841.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;h3 id="detr-模型结构">DETR 模型结构&lt;/h3>
&lt;p>前面已经讲解完训练损失的关键部分：bipartite matching loss，接下来开始更加细致地分析 DETR 的整体结构，看看 transformer 在目标检测中可以怎样设计。模型的详细结构图如下所示：
&lt;img src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216133428.png" alt="">&lt;/p>
&lt;p>总共包括四个部分：CNN骨干网络 backbone、encoder、decoder，prediction heads，接下来分别介绍这四个部分。&lt;/p>
&lt;p>1） CNN 骨干网络 backbone
DETR 利用 CNN 骨干网络从原始像素值中提取特征，假设一张图的大小为 \(3*H_0*W_0\) , 通过 backbone 之后，以 resnet50 为例，将会得到一个 feature map，大小为 \(C*H*W\) （ \(H=H_0/32\) , \(W=w_0/32\) , \(C=2048\)）。&lt;/p>
&lt;p>2） encoder
encoder 首先使用一个 \(1*1\) 的卷积来减少 feature map 的维度，把 C 变成一个更小的维度 d, 得到一个新的 feature map \(d*H*W\) 。由于 encoder 希望得到的输入是一个序列，所以 DETR 把空间维度拉直变成了一维，得到一个 \(d*HW\) 的feature map，其实就是原始 feature map 中的一个点代表 nlp 里面的一个词。&lt;/p>
&lt;p>DETR transformer 的 encoder 与标准的 transformer 基本一致，如下图所示：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216135014.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216135014.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>encoder 部分主要包含一个 multi-head self-attention 模块以及一个 FFN 网络。虽然整体结构和标准的 transformer 基本一样，但是还是有一些不同的地方。&lt;/p>
&lt;p>a) 考虑 2d 空间的 Spatial positional encoding&lt;/p>
&lt;p>传统的 transformer 的 position encoding 都是 1D 的，但是对于视觉任务，很明显具有 2D 的关系，因此作者设计 Spatial positional encoding 考虑了两个 xy 两个方向，具体的编码方式采用的是 sincos 的形式。因为 position encoding 最后是要和feature相加的，所以它的维度也是 d 维，在实现上就是先对 x 方向进行编码得到维度维 d/2 的向量，再对 y 方向进行编码同样得到维度为 d/2 的向量，最终将二者 concat 到一起。&lt;/p>
&lt;p>b) 仅 K 和 Q 上添加了 Spatial positional encoding&lt;/p>
&lt;p>这里给出标准 transformer 的结构图示意图：
&lt;img src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216140242.png" alt="">&lt;/p>
&lt;p>可以看到 positional encoding 是加在 Q，K V 上的，而 DETR 这里仅加在了 Q 和 K 上，作者也没解释为什么这样加,大概因为目标检测任务对位置更加敏感，所以在整个过程中都加入位置信息。&lt;/p>
&lt;p>3）decoder&lt;/p>
&lt;p>DETR transformer 的 decoder 和标准的 transformer 的 decoder 有很多的不同之处。&lt;/p>
&lt;p>a) 并行解码所有元素&lt;/p>
&lt;p>由于预测的目标之间是无序的，DETR可以一次性将 N 个目标框预测出来，因此在解码时不需要向标准的 transformer 一样进行顺序解码。回想一下标准 transformer 解码器的工作流程，首先输入一个起始的 token BOS_WORD, 然后解码器预测第一个元素，将开始 BOS_WORD 和第一个元素送入 decoder，然后得到第二个元素，依次进行下去知道得到结束的 token 才终止。然而在 DETR 中，只需要初始化一个全 0 的token，然后加上对应的 position encoding（文章叫做 object query，后面将详细阐述）一起送入到 decoder 中，直接得到 N 个目标框的预测结果。&lt;/p>
&lt;p>b) Object Query&lt;/p>
&lt;p>DETR 中在 decoder 部分提出了一个 Object Query 的概念，可以简单理解为标准的 transformer 中的 position encoding，形式上差不多。但是在 DETR 中主要是为了得到目标物体与全局图像之间的关系，简单来说就是一些关于目标在图像中的一些关系，比如大小、位置、类别等信息，每一个 query 相当于融合和了整个数据集中所有类别在某个位置具有多大的目标。Object query 首先计算一个 self-attention，然后和 encoder 得到的 k，v 计算新的 feature。值得注意的是，这里计算 self-attention 的时候，object query 和 encoder 的 positional encoding 一样，也只加在了 k，q 中，没有加到 v 上。&lt;/p>
&lt;p>c) decoder 中计算 cross-attention 时都加上了 positional encoding&lt;/p>
&lt;p>仔细对比标准的 transformer 的 encoder 和 DETR 的 encoder 可以发现，标准的 transformer 在 decoder 中，接收的 encoder 输出没有添加 positional encoding，而在 DETR 中，作者认为 positional encoding 在 decoder 中也非常重要，主要还是因为目标检测是一个和位置强相关的任务。&lt;/p>
&lt;p>4）Prediction Heads&lt;/p>
&lt;p>Prediction Heads 主要是得到分类结果和目标框的坐标，就是一些全连接层，比较简单。除了最后一个 decoder 计算损失函数外，作者添加了一些辅助的损失函数，就是将每一个 decoder 的输出都用同样的 prediction Heads 来计算损失，这样可以进一步提升模型的性能。&lt;/p>
&lt;h3 id="实验结果">实验结果&lt;/h3>
&lt;p>在实验部分，backbone 主要是 resnet50/101，以及为了提升特征的分辨率，使用了空洞卷积，最后得到的 feature 少降低一倍分辨率，当然分辨率的提高也引来了更大的计算消耗。&lt;/p>
&lt;p>主要的实验结果如下表所示：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216150402.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216150402.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>图中的模型都是通过 Detectron2 来实现的，普通的 Faster RCNN 训练 3x schedule ，然后 “+” 代表 9x schedule （109 epoches），可以看到 DETR 模型的效果基本可以达到甚至超越 Faster RCNN 的结果。但是从表里也可以发现 DETR 的一些劣势，特别是在小目标上的检测精度上。&lt;/p>
&lt;p>作者对模型做了很多消融实验并且提供了很多的图示进行解释。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>encoder 的层数&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216151241.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216151241.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>结论是基本上 encoder 的层数越多，效果是越好的&lt;/p>
&lt;/li>
&lt;li>
&lt;p>encoder self-attention 可视化&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152108.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152108.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>作者对最后一层 encoder 出来的 attention maps 进行了可视化，选取了几个目标中的参考点，然后可视化对于参考点的 attention，可以看出这些参考点的 attention 已经能够将目标区分出来，这样可以简化后面 decoder 的精确定位。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>decoder 的层数&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152524.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152524.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>DETR 的每一层 decoder layer 都会输出对应的预测结果，作者对每一层输出的预测结果进行评估，可以发现当然层数是越多越好，而且 DETR 不需要进行 NMS，说明 DETR 不会产生冗余的预测。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>decoder attention 可视化&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152836.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216152836.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>同样地，作者对 decoder 的 attention 也进行了可视化，每一个能够检测到目标的 query，对应的 attention 如上图所示，可以看出 decoder 的 attention 激活值比较大的地方确实主要在目标的边界。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>positional encoding 的重要性&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216154640.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216154640.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>DETR 中有三个地方需要 positional encoding，一个是 encoder 的输入，一个是 decoder 的 cross attention 的部分，最后一个是 decoder 的 self-attention 部分。表中 at input 表示只在 encoder 或者 decoder 的输入的地方添加 positional encoding，这是标准的 transformer 中使用的策略。at attn 就是 DETR 的方式，在 encoder 或 decoder 每一层都添加了对应的 position encoding。由于 object query 是必须的，所以作者在这个实验没有去除 decoder 的 object query。从表中可以看到，如果去除 encoder 和 decoder 中的 positional encoding 后，模型的检测精度将会极速下降。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>decoder output slot 分析&lt;/p>
&lt;p>这里的 decoder output slot 其实就是 object query，作者通过可视化 COCO 2017 val 数据集上所有图片的 box 预测结果，从 100 个预测中选取了 20 个 DETR decoder 的结果。其中不同的颜色代表点代表 box 的不同大小，绿色为小目标，红色为大目标。点的位置代表了目标的中心位置。可以看出，不同的 object query 学习到了在某个位置，特定大小目标的 patten。作者提到 COCO 数据集中就存在很多和图像大小差不多的 box，所以大多数 slots 都会预测中心区域然后很大的目标框。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216160345.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216160345.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>泛化到没有见过的目标数量&lt;/p>
&lt;p>COCO 数据集中很多目标都不会出现太多次，特别是一个类别的目标不会在图像中多次出现，所以一个很自然的疑问就是 DETR 能够泛化到未知目标数量的图像上吗？因此作者做了一个实验，将 24 个长颈鹿拼在一起，然后送入 DETR 模型检测，可以看到模型依然能够检测出来，这说明 每个 object query 不会有很强的关于类别的偏见。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216160743.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216160743.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;h2 id="个人评价">个人评价&lt;/h2>
&lt;p>毫无疑问 DETR 是一个开创性的工作，直接把 transformer 引入到目标检测中，把目标检测任务当做一个点集预测的任务，实现目标检测真正的 end-to-end。但是也有一些问题:&lt;/p>
&lt;ol>
&lt;li>不够纯粹。在刚出来的时候，很多人认为 DETR 是一个残次品，是 CNN 和 transformer 的组合。所以没有引起很多的关注，知道 ViT 的出现，vision transform 才开始急速发展。&lt;/li>
&lt;li>收敛速度慢，资源消耗多。DETR 训练需要的资源消耗也让很多人望而却步，作者在 COCO 数据集上训练 DETR 需要至少 300 epoch，使用 16 张 V100 需要训练三天才能收敛。&lt;/li>
&lt;li>在小目标上表现欠佳。&lt;/li>
&lt;/ol>
&lt;p>后续基于 DETR 的工作主要集中解决后两个问题，使得模型收敛更快，性能更好。&lt;/p></description></item><item><title>Vision Transformer 在目标检测上的探索，DETR 系列文章解读（二）Deformable DETR</title><link>https://kinredon.github.io/post/vision-transformer-for-object-detection_2/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/vision-transformer-for-object-detection_2/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>针对 DETR 收敛慢资源消耗多，小目标检测难的问题，Jifeng Dai 团队做出了 Deformable DETR，根据 Deformable convolution 的思想对 DETR 进行改进，即让注意力模块只注意到参考点周围的少量样本点。如下图所示，作者提出的 Deformable DETR 把多尺度的 feature map 送入 encoder 中，在 encoder 中，下一层的 feature 由上一层的参考点周围的少量点决定，最终将 encoder 的多次度特征再送到 decoder 中，最终输出预测的结果。&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216192053.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216192053.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;h2 id="正文">正文&lt;/h2>
&lt;p>Deformable DETR 的核心在于 Deformable Attention Module，该模块用于直接替换 DETR 中的 multi-head self-attention 模块，由于 Deformable DETR 在计算 attention 的时候只考虑参考点周围的几个偏移点，大大的减少了计算量，因此也可以使得模型能够扩展到 multi-scale，进一步提升模型在不同尺度目标上的检测性能。&lt;/p>
&lt;h3 id="deformable-attention-module">Deformable Attention Module&lt;/h3>
&lt;p>Deformable DETR 的主要贡献便是提出了一个 Deformable Attention Module 的模块，该模块可以用于替换 encoder 中的 self-attention 模块，能极大地减少计算量。由于 query feature 仅与参考点周围的 K 个样本做交互，实现中 K=4，因此计算量大大减少。减少计算量的同时，由于限制了 attention 的范围，相当于加入了一些先验知识，使得模型收敛更快。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216194118.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216194118.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>Deformable Attention Module 的具体设计入上图所示，首先一个 Query Feature \(z_q\) 经过两个 linear 层，分别生成 \(2*MK\) 和 \(MK\) 的 offset 和 attention weight。根据对应的参考点（其实就是 query 在 feature map 中的位置）预测 offset，计算新的坐标点，采集这些新坐标点特征并用 attention weight 进行加权融合信息，最终将多个 head 的信息 concat 到一起。形式化的定义如下：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225163158.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225163158.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>其中 x 是一个 \(C*H*W\) 的 feature map， \(\boldsymbol{W}_{m}^{\prime}\) 是一个 1*1 的卷积层，用于降低 channel 的维度， \(\boldsymbol{p}_{q}\) 是参考点， \(\Delta \boldsymbol{p}_{m q k}\) 是用 query feature 预测得到的 offset，从feature map 中得到参考点 \(\boldsymbol{p}_{q}\) 周围的特征，通过 attention weight 加权求和得到新的 feature。&lt;/p>
&lt;h3 id="multi-scale-deformable-attention-module">Multi-scale Deformable Attention Module&lt;/h3>
&lt;p>为了解决多尺度目标检测的问题，作者提出了 Multi-scale Deformable Attention Module，主要的差别是将不同层的 feature 融合在一起，多了一个 scale 的维度，如下：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225163249.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211225163249.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>其中 \(\phi_{l}\) 是一个映射函数，将参考点的位置映射回对应的 feature map 层级。&lt;/p>
&lt;h3 id="deformable-transformer-encoder">Deformable transformer encoder&lt;/h3>
&lt;p>在实现上，作者使用了四层的 feature map 作为多尺度特征，前三层是 ResNet 的 \(C_3\) 和 $C_5$，最后一层通过在最后的 \(C_5\) 层后加一个 \(3*3，stride=2\) 的卷积层得到，记为 \(C_6\) 。所有的多尺度 feature maps 都转化为同一个 channel 大小 \(C=256\) ，入下图所示：&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216200200.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211216200200.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>为了在学习过程中，模型能够知道对应的特征来着哪一个层级，作者在 positional encoding 里面还加入了随机初始化科学系的 scale-level 的 positional encoding。&lt;/p>
&lt;h3 id="deformable-transformer-decoder">Deformable transformer decoder&lt;/h3>
&lt;p>在 decoder 中，每一个 decoder layer 有 self-attention 和 cross-attention 两个部分，self-attention可以直接从计算 object query。而 object query 在 cross-attention 对应的参考点则使用一个可学习的 linear layer 来学习。由于最终抽取的特征是在一个参考点周围的图像特征，所以作者将检测头也设计为预测针对参考点的 offset 而不是绝对坐标。&lt;/p>
&lt;h3 id="deformable-detr-的两个变体">Deformable DETR 的两个变体&lt;/h3>
&lt;p>作者还设计了两个 Deformable DETR 的变体，分别是进行迭代式的 bounding boxes 修正，以及 two-stage Deformable DETR。&lt;/p>
&lt;ol>
&lt;li>迭代式的 bounding boxes 修正&lt;/li>
&lt;/ol>
&lt;p>decoder 的每一层修正上一层的预测，即上一层的预测的结果输入到下一层。&lt;/p>
&lt;ol>
&lt;li>Two-Stage Deformable DETR&lt;/li>
&lt;/ol>
&lt;p>从 two-stage 目标检测器得到启发，作者首先利用一个 FFN 在 encoder 的 feature 上得到初始的 region proposal，挑选其中分数较高的 proposal 用于后续的优化。具体来说，作者将分数较高的 proposal 当做迭代式的 bounding boxes 修正的初始点。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Deformable DETR 通过将 Deformable Conv 的思想引入 DETR，不仅减少了计算量，而且提高了模型的收敛速度。在实验部分，Deformable DETR 仅需要 50 epochs 便能达到 DETR 需要 500 epochs 达到的效果，相当于 10x 的收敛速度，而且精度更高。&lt;/p></description></item><item><title>【收藏向】快速完成在线会议视频录制（视频转换 + 字幕制作）</title><link>https://kinredon.github.io/post/presentation_for_online_academic_conference/</link><pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/presentation_for_online_academic_conference/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>最近由于疫情原因，国际出行难度变高，不少 AI 学术会议采用线上的形势，比如 ICCV, CVPR 等等。线上会议通常不仅要求 oral paper 录制视频讲解论文内容，还要求 poster 同样需要录制视频内容。基于此，本文记录如何快速进行视频录制，并进行字幕的制作。建议收藏，下次遇到线上会议需要录制视频，直接按照步骤开始即可。在这个过程中，有更好地工具也欢迎私信我。&lt;/p>
&lt;p>主要的过程和使用的工具如下：&lt;/p>
&lt;ol>
&lt;li>视频录制：做好 PPT 后，在每一页 PPT 录制对应的音频，导出时选择导出方式为 mp4 即可；&lt;/li>
&lt;li>字幕制作：【网易见外】智能识别字幕，在 ArcTime 中对字幕进行矫正，然后导出；&lt;/li>
&lt;/ol>
&lt;h2 id="视频录制">视频录制&lt;/h2>
&lt;p>我认为使用 PPT 每一页录制音频后导出 mp4 做线上学术视频有两个主要的好处：&lt;/p>
&lt;ol>
&lt;li>使用方便，节省时间&lt;/li>
&lt;li>方便修改讲解内容：想象一下如果使用屏幕录制软件制作视频，中间部分讲错了发挥不好又需要重新录制，PPT 录制只需要录制对应页的音频即可；&lt;/li>
&lt;/ol>
&lt;p>对每一页 slide 录制对应的音频，通过工具栏：插入（insert）&amp;ndash;&amp;gt;音频（Audio）&amp;ndash;&amp;gt; 录制音频（Audio Record）实现，录制完成后可以看到一个播放的小图标：&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105142108.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105142108.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;p>可以反复听，不满意再重新录制。录制完成后导出，选择导出为 mp4 文件后可以得到一个文件后缀为 .mp4 的文件（不知道为什么，我的 MacBook 无法完成这一步，用同学的 Windows 电脑可以，orz）。&lt;/p>
&lt;h2 id="字幕制作">字幕制作&lt;/h2>
&lt;p>这里推荐使用&lt;a href="https://jianwai.youdao.com/">网易见外&lt;/a>,可以直接上传视频后得到对应识别好的英文字幕文件。有人要说了，稿子我都写了要它识别干嘛？其实这里主要是为了得到分割好的片段，比如视频哪一段对应哪一段字幕，不用自己在剪辑软件里面一个一个片段黏贴，我们只需要修正一下识别错误的地方。步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>申请账号 &lt;a href="https://jianwai.youdao.com/">网易见外&lt;/a>，省略。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>选择新建项目，选择视频转写生成字幕文件，生成之后可以进行在线矫正，最终导出字幕。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105143422.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105143422.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105143530.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211105143530.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;/li>
&lt;/ol>
&lt;h2 id="字幕嵌入">字幕嵌入&lt;/h2>
&lt;p>有了字幕文件，接下来该将字幕文件嵌入到视频中了，这里使用 &lt;a href="https://arctime.org/">ArcTime Pro&lt;/a> 软件。只是嵌入字幕是非常简单的，视频导入进去后，把字幕导入，然后直接导出就可以了。这其中可能有个问题：文本太长超出屏幕显示范围，可以直接把 &lt;code>\n&lt;/code> 放在你想换行位置，这样问题就得到解决了。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>这篇文章主要讲怎么快速的制作一个在线学术会议的视频并添加字幕，为了让研究者专注于视频内容的创作，简化整个过程。如果有些会议有特殊的要求，比如需要视频中出现人脸，可以使用腾讯会议这样的工具。或者大家觉得口语不太好，不想念稿子，也可以使用 &lt;a href="https://aws.amazon.com/cn/polly/">Amazon Polly&lt;/a> 这样的文本转语音软件。&lt;/p></description></item><item><title>参加VALSE 2021的几点总结</title><link>https://kinredon.github.io/post/valse2021/</link><pubDate>Wed, 13 Oct 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/valse2021/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>很幸运能有机会前往杭州参加 VALSE 2021，之前就一直关注 VALSE 的线上活动，也在线听了不少 VALSE 的 webinar，都是计算机视觉各个研究方向的优秀青年学者来做讲座。VALSE 2021 年度大会，邀请了很多大佬做 tutorial 和 workshop 的讲解，整体参与下来，也算收益良多。接下来简单聊一下我的感想并做几点总结。&lt;/p>
&lt;h2 id="几点总结">几点总结&lt;/h2>
&lt;p>&lt;strong>&lt;strong>徐宗本院士：如何突破机器学习的先验假设？&lt;/strong>&lt;/strong> 起初我只当这是一个普通的讲座，但从一开始就感受到了院士的气场，自信而不张扬，听出了其对机器学习的深刻认识，瞬间激起了我的兴趣。讲座一开始给出了一个大一统的公式指出现有机器学习范式主要包括五个部分：模型假设空间、损失函数、正则项、数据空间、优化算法，并指出了各个部分的局限性，最终针对这五个部分给出了一些解决方案，相应的探索也有些突破。很多部分之前都没听说过，但不明觉厉，这是真正的具有前瞻性的研究，令人大开眼界。&lt;/p>
&lt;p>&lt;strong>&lt;strong>迁移学习年度进展汇报&lt;/strong>&lt;/strong> 由于我的主要研究方向是迁移学习，所以我对此方向的汇报关注都比较高。之前听过张磊老师的报告，对迁移学习领域自适应方向的讲述很全面。这次年度进展汇报给予了新的惊喜，张老师给出了十个迁移学习当前的研究方向，主要如下图所示：
&lt;img src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211013000524.png" alt="">
有些工作之前关注过，但却没有进行系统的梳理，但这对整个领域的认识还是很重要的。后续有机会对每一个方向进行细致的讲述，不知道有没有人看。&lt;/p>
&lt;p>&lt;strong>&lt;strong>Vision Transformer 锋芒毕露，势不可挡&lt;/strong>&lt;/strong> 此次大会 Vision Transformer 占有很大比重，tutorial 和 workshop 都有，如香港大学罗平老师的《Vision Transformer for Object Detection and Scene Segmentation》和曹越老师的 Transformer tutorial。Vision Transformer 之前给我的感觉仅仅是计算机视觉一个新兴的研究方向，很火但还很初级，虽然听过 Swin Transformer 这样大杀器，知道重要性，但一直没有认真地关注它。此次大会发现其开始在各个领域大放异彩，如backbone网络的 VIT，CMT，Swin等，以及在各个 high level 视觉任务中的突破如检测 DETR，分割里面的 segformer 等。在视觉任务竞赛中现有很多 Top 解决方案中开始采用 Vision Transformer。本次大会让我更加地重视 Vision Transformer，锋芒毕露，势不可挡。总的来说，Vision Transformer对深度学习意义重大，大家赶快进军 Vision Transformer。&lt;a href="https://www.msra.cn/zh-cn/news/features/cv-transformer">为何Transformer在计算机视觉中如此受欢迎？&lt;/a>&lt;/p>
&lt;p>&lt;strong>&lt;strong>算力支撑起来的大规模预训练模型&lt;/strong>&lt;/strong> Google Brain 研究员翟晓华指出大规模数据、大模型、超长 training schedule 相辅相成，能够得到极好的预训练模型，大大提升模型在 finetune 后的性能，其中最受震撼的就是，同一个任务 8 张 GPU 训练一周和一个月模型的性能有较大差距，所以算力才是 yyds。&lt;/p>
&lt;p>&lt;strong>&lt;strong>下游任务的无监督表征学习&lt;/strong>&lt;/strong> 近期无监督表征学习得到广泛地研究，利用自监督方法让模型学习到更好的表征，主要包括 pretext task 和 contrastive learning。pretext task 利用数据手动创造一些标签用于给模型额外的监督信号，如旋转角度预测，patch排序，mask 预测等。contrastive learning 自 moco 以来出现了很多有意思的工作，利用对比的思想，构造正负样本对，拉近正样本对的距离，分离负样本对，实现鲁棒特征的学习。这些通过无监督表征学习的得到的特征更具判别力，在 imageNet 上进行 linear classification 的精度不断提高。然而目前这些工作对下游任务如检测、分割的提升非常有限，然而这些任务又极其重要，因此现在有很多 contrastive 的方法用于类似这样 dense prediction 任务的情况，比如 pixel-to-propagation 用来做分割。&lt;/p>
&lt;p>&lt;strong>&lt;strong>Poster &amp;amp; AI 公司&lt;/strong>&lt;/strong> 很喜欢 Poster 这一环节，可以去看自己喜欢的 paper，有问题能够直接和作者面对面交流，也能认识很多大佬。VALSE 的赞助商很多，包含国内很多优秀的 AI 公司或者实验室，直接去他们摊位交流还是很有效的。观察来看，感觉自动驾驶公司还是蛮多的，其次是各大公司的实验室，以及初创公司。大家为了抢人使出浑身解数，感觉最有效的方式就是抽奖了，这次感觉极视平台下了血本，服务器都给抽了：）就是个人运气不太好，看来永远不能成欧皇了哈哈哈。&lt;/p>
&lt;p>&lt;strong>&lt;strong>其它&lt;/strong>&lt;/strong> 这篇总结主要是在飞机上用手机凭记忆打出，听的时候没有拍照记录，所以很多细节记录不清。因此还有一些有意思的讲座上面没有提及，包括黄高老师的动态网络、崔鹏老师的OOD，stable learning，彭玺老师的 contrastive clustering 等等，希望后续 VALSE 能够 release slides，可以及时复习。其它有意思的讲座有很多，但受限于个人精力，仅看了部分的讲座。整个 VALSE 大会对我来说唯一遗憾的是，后面的 tutorial 和 workshop 没有迁移学习的 section，很多工作都穿插在了自监督和无监督的讲座里面。&lt;/p></description></item><item><title>如何利用 org mode 写博客</title><link>https://kinredon.github.io/post/org-mode-blog-configuration/</link><pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/org-mode-blog-configuration/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>阅读本文需要一定的 emacs 和 org mode 使用基础，并阅读 &lt;a href="https://kinredon.github.io/post/how-to-publish-personal-website-on-github/">使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上&lt;/a> 。&lt;/p>
&lt;p>由于我经常使用 &lt;a href="https://orgmode.org/">org mode&lt;/a> 进行 gtd、项目管理、记录笔记，因此计划写文章也用 &lt;a href="https://orgmode.org/">org mode&lt;/a> 来实现。 &lt;a href="https://orgmode.org/">org mode&lt;/a> 通常基于编辑器 emac 使用，是一种类似于 markdown 的标记语言，通过简单的符号定义，得到格式化的文章效果，关于 &lt;a href="https://orgmode.org/">org mode&lt;/a> 的使用可以参考&lt;a href="https://www.cnblogs.com/open%5Fsource/archive/2011/07/17/2108747.html">Org-mode 简明手册&lt;/a>。 &lt;a href="https://orgmode.org/">org mode&lt;/a> 具有强大的文档导出功能，比如 pdf，markdown，html 等，如果你没有使用过 org mode，强烈建议学习使用。之前使用了 Hugo 搭建了个人博客，虽然 Hugo 原生支持 org mode，但是实际效果不是很理想，毕竟没有像 markdown 应用广泛。因此基本思路是用 org mode 写文章，然后转化为 markdown 文本，幸运的是 emacs 社区具有相应的支撑。&lt;/p>
&lt;p>主要使用到两个工具： &lt;code>easy-hugo&lt;/code> 和 &lt;code>ox-hugo=， =easy-hugo&lt;/code> 用来管理 Hugo 的文章， &lt;code>ox-hugo&lt;/code> 用来将 org mode 文章转化为 markdown 格式。&lt;/p>
&lt;p>关于如何使用 Hugo 搭建文章，可以查看 &lt;a href="https://kinredon.github.io/post/how-to-publish-personal-website-on-github/">使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上&lt;/a>。&lt;/p>
&lt;h2 id="easy-hugo-的安装与使用">easy-hugo 的安装与使用&lt;/h2>
&lt;p>查看 easy hugo 官网&lt;a href="https://github.com/masasam/emacs-easy-hugo"> emacs-easy-hugo&lt;/a>，可以发现 easy hugo 可以实现在 emac 上管理 Hugo 文章，如下图所示：&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211005133605.png" alt="Figure 1: 图源：![](https://github.com/masasam/emacs-easy-hugo/blob/master/image/easy-hugo-mode.png)"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211005133605.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 1: 图源：![](https://github.com/masasam/emacs-easy-hugo/blob/master/image/easy-hugo-mode.png)&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>安装 easy hugo 通过 &lt;code>MELPA&lt;/code> ，即 &lt;code>M-x package-install easy-hugo&lt;/code> 配置如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-emacs-lisp" data-lang="emacs-lisp">&lt;span class="p">(&lt;/span>&lt;span class="nb">use-package&lt;/span> &lt;span class="nv">easy-hugo&lt;/span>
&lt;span class="nb">:init&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">easy-hugo-basedir&lt;/span> &lt;span class="s">&amp;#34;~/Documents/sync/blogs/kinredon.github.io&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">;; 网站本地文件根目录&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">easy-hugo-url&lt;/span> &lt;span class="s">&amp;#34;https://kinredon.github.io&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">;; url 路径&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">easy-hugo-sshdomain&lt;/span> &lt;span class="s">&amp;#34;kinredon.github.io&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">easy-hugo-previewtime&lt;/span> &lt;span class="s">&amp;#34;300&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">easy-hugo-default-ext&lt;/span> &lt;span class="s">&amp;#34;.org&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nb">:bind&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;C-c C-e&amp;#34;&lt;/span> &lt;span class="o">.&lt;/span> &lt;span class="nv">easy-hugo&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>利用 &lt;code>C-x C-e&lt;/code> 执行命令，然后 &lt;code>M-x easy-hugo&lt;/code> 进入博客管理界面。&lt;/p>
&lt;h2 id="ox-hugo-的安装与配置">ox-hugo 的安装与配置&lt;/h2>
&lt;p>ox-hugo 可以完美转换 org mode 到 markdown，使用 &lt;code>MeLPA&lt;/code> 安装，即 &lt;code>M-x package-install ox-hugo&lt;/code> ，配置如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-emacs-lisp" data-lang="emacs-lisp">&lt;span class="p">(&lt;/span>&lt;span class="nb">use-package&lt;/span> &lt;span class="nv">ox-hugo&lt;/span>
&lt;span class="nb">:init&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">org-hugo-base-dir&lt;/span> &lt;span class="s">&amp;#34;~/Documents/sync/blogs/kinredon.github.io&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1">;; 本地网站根目录&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">setq&lt;/span> &lt;span class="nv">org-hugo-default-section-directory&lt;/span> &lt;span class="s">&amp;#34;post&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nb">:ensure&lt;/span> &lt;span class="no">t&lt;/span>
&lt;span class="nb">:after&lt;/span> &lt;span class="nv">ox&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>至此，我们的配置完成，可以愉快地使用 org mode 撰写文章，自动转换到 markdown 格式，利用 hugo 生成静态网站，推送到 GitHub pages 上，也可以将 markdown 格式的文件传到其他支持 markdown 文章导入的平台，如知乎，微信公众号。&lt;/p>
&lt;p>接下来介绍一下我写文章的工作流。&lt;/p>
&lt;h2 id="工作流">工作流&lt;/h2>
&lt;p>我将 org mode 写的文章与生成的 markdown 文章分别管理，即在网站根目录添加 &lt;code>org&lt;/code> 目录：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">cd&lt;/span> kinredon.github.io
mkdir org
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>org&lt;/code> 目录中存储所有使用 org mode 写的文章，转化后的 markdown 文件存储在 &lt;code>./content/post&lt;/code> 目录下，利用 easy hugo 管理。由于我不想上传 org 文件，因此我在 &lt;code>.gitignore&lt;/code> 中加入 &lt;code>org&lt;/code> 让 git 忽略此文件目录下的内容。&lt;/p>
&lt;p>工作流步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>撰写 org mode 文章，并存储在 &lt;code>org&lt;/code> 目录下&lt;/p>
&lt;p>用 org mode 写文章有两种方式，一种是所有文章存储在一个 org 文件里面，不同的 subtree 为一个文章，利用 org capture 新建博文，生成模板文件，然后利用 org refile 将文章保存在不同的位置，这种方式&lt;a href="https://www.xianmin.org/post/ox-hugo/">这里&lt;/a>有讲解。我采用的方式为一篇文章一个 org 文件， 我们使用 &lt;code>snippet&lt;/code> 模板, 即添加 &lt;code>snippet&lt;/code> 模板：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-emacs-lisp" data-lang="emacs-lisp">&lt;span class="err">#&lt;/span> &lt;span class="nv">-*-&lt;/span> &lt;span class="nv">mode:&lt;/span> &lt;span class="nv">snippet&lt;/span> &lt;span class="nv">-*-&lt;/span>
&lt;span class="err">#&lt;/span> &lt;span class="nv">name:&lt;/span> &lt;span class="nv">hugo&lt;/span>
&lt;span class="err">#&lt;/span> &lt;span class="nv">key:&lt;/span> &lt;span class="nv">h&lt;/span>
&lt;span class="err">#&lt;/span> &lt;span class="nv">--&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_BASE_DIR:&lt;/span> &lt;span class="nv">path-to/kinredon.github.io&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+TITLE:&lt;/span> &lt;span class="nv">$1&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+DATE:&lt;/span> &lt;span class="o">`&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nf">format-time-string&lt;/span> &lt;span class="s">&amp;#34;%Y-%m-%d&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">`&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_AUTO_SET_LASTMOD:&lt;/span> &lt;span class="no">t&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_TAGS:&lt;/span> &lt;span class="nv">$2&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_CATEGORIES:&lt;/span> &lt;span class="nv">$3&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_DRAFT:&lt;/span> &lt;span class="nv">false&lt;/span>
&lt;span class="err">#&lt;/span> &lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_MENU:&lt;/span> &lt;span class="nb">:menu&lt;/span> &lt;span class="s">&amp;#34;main&amp;#34;&lt;/span> &lt;span class="nb">:parent&lt;/span> &lt;span class="s">&amp;#34;docs&amp;#34;&lt;/span> &lt;span class="nb">:weight&lt;/span> &lt;span class="mi">3&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+options:&lt;/span> &lt;span class="nv">author:nil&lt;/span>
&lt;span class="err">#&lt;/span>&lt;span class="nv">+HUGO_CUSTOM_FRONT_MATTER:&lt;/span> &lt;span class="nb">:katex&lt;/span> &lt;span class="nv">true&lt;/span>
&lt;span class="nv">$0&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>保存后，我们新建 org 文件后，输入 &lt;code>h&lt;/code> 然后使用 &lt;code>tab&lt;/code> 就可生成模板文件，如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">#+HUGO_BASE_DIR: path-to/kinredon.github.io
#+TITLE:
#+DATE: 2021-10-05
#+HUGO_AUTO_SET_LASTMOD: t
#+HUGO_TAGS:
#+HUGO_CATEGORIES:
#+HUGO_DRAFT: false
# #+HUGO_MENU: :menu &amp;#34;main&amp;#34; :parent &amp;#34;docs&amp;#34; :weight 3
#+options: author:nil
#+HUGO_CUSTOM_FRONT_MATTER: :katex true
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>导出 markdown 文件， &lt;code>C-c C-e H h&lt;/code> 导出&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211005140343.png" />
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211005140343.png" itemprop="contentUrl">&lt;/a>
&lt;/figure>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>预览&lt;/p>
&lt;p>通过 &lt;code>M-x easy-hugo&lt;/code> 打开 easy hugo，然后选中新生成的文章，然后按 &lt;code>p&lt;/code> 即可预览生成的文章。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>部署&lt;/p>
&lt;p>利用 &lt;a href="https://kinredon.github.io/post/how-to-publish-personal-website-on-github/">使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上&lt;/a> 中的 &lt;code>deploy.sh&lt;/code> 将文章推送到远程服务器。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;span class="cp">&lt;/span>git add .
git add org/img &lt;span class="c1"># 用来存储图像的目录，后续将会用到&lt;/span>
git commit -m &lt;span class="s2">&amp;#34;update article&amp;#34;&lt;/span>
git push
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>至此，可以在远程访问个人网站啦。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="其它">其它&lt;/h2>
&lt;p>在写作过程中发现一些小问题，比如文章图片的管理，文献管理等，这里介绍一下我的解决方案，后续遇到新的问题，再持续更新。&lt;/p>
&lt;h3 id="图片管理">图片管理&lt;/h3>
&lt;p>我将图片放在 &lt;code>./org/img&lt;/code> 目录下，普通的图片直接放在该目录下，然后在 org 文件中引用即可，然而我们写文章时常常喜欢截图，每次截图后保存非常的麻烦，因此利用一个 elisp 小函数实现该功能：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-emacs-lisp" data-lang="emacs-lisp">&lt;span class="p">(&lt;/span>&lt;span class="nb">defun&lt;/span> &lt;span class="nv">my/file-paste&lt;/span> &lt;span class="p">()&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">interactive&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">let*&lt;/span> &lt;span class="p">((&lt;/span>&lt;span class="nv">org-fpath&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">buffer-file-name&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">window-buffer&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">minibuffer-selected-window&lt;/span>&lt;span class="p">))))&lt;/span>
&lt;span class="c1">;; (dst_dpath (expand-file-name (concat (if org-fpath (file-name-base org-fpath) &amp;#34;~/Desktop/scratch&amp;#34;) &amp;#34;_&amp;#34; &amp;#34;assets&amp;#34;)))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">dst_dpath&lt;/span> &lt;span class="s">&amp;#34;./img&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">src_fpath&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">string-trim&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">shell-command-to-string&lt;/span> &lt;span class="s">&amp;#34;/Users/kinredon/Documents/Scripts/clipboard/clipboard_file.sh&amp;#34;&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">src_name&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">file-name-base&lt;/span> &lt;span class="nv">src_fpath&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">src_ext&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">file-name-extension&lt;/span> &lt;span class="nv">src_fpath&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">dst_fpath&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">concat&lt;/span> &lt;span class="nv">dst_dpath&lt;/span> &lt;span class="s">&amp;#34;/&amp;#34;&lt;/span> &lt;span class="nv">src_name&lt;/span> &lt;span class="s">&amp;#34;_&amp;#34;&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">format-time-string&lt;/span> &lt;span class="s">&amp;#34;%Y%m%d%H%M%S&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="s">&amp;#34;.&amp;#34;&lt;/span> &lt;span class="nv">src_ext&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">when&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">not&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">file-exists-p&lt;/span> &lt;span class="nv">dst_dpath&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nv">make-directory&lt;/span> &lt;span class="nv">dst_dpath&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">file-exists-p&lt;/span> &lt;span class="nv">src_fpath&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">progn&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">copy-file&lt;/span> &lt;span class="nv">src_fpath&lt;/span> &lt;span class="nv">dst_fpath&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nf">insert&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">concat&lt;/span> &lt;span class="s">&amp;#34;[[file:&amp;#34;&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nv">file-relative-name&lt;/span> &lt;span class="nv">dst_fpath&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nf">file-name-directory&lt;/span> &lt;span class="nv">org-fpath&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="s">&amp;#34;]]&amp;#34;&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nf">message&lt;/span> &lt;span class="nv">src_fpath&lt;/span>&lt;span class="p">))))&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="nb">use-package&lt;/span> &lt;span class="nv">org&lt;/span>
&lt;span class="nb">:ensure&lt;/span> &lt;span class="no">nil&lt;/span>
&lt;span class="nb">:mode&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;\\.org\\&amp;#39;&amp;#34;&lt;/span> &lt;span class="o">.&lt;/span> &lt;span class="nv">org-mode&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="nb">:bind&lt;/span>
&lt;span class="p">(&lt;/span>
&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;C-x C-y&amp;#34;&lt;/span> &lt;span class="o">.&lt;/span> &lt;span class="nv">my/file-paste&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="p">))&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 org 文件中， &lt;code>C-x C-y&lt;/code> 自动调用 &lt;code>file-paste&lt;/code> 函数，将截图自动存储在 &lt;code>img&lt;/code> 目录下，然后生成对应的引用。&lt;/p>
&lt;h3 id="文献应用">文献应用&lt;/h3>
&lt;p>由于我喜欢写论文阅读笔记，常常需要应用文献，关于文献管理，我使用的 &lt;code>org-ref&lt;/code> 统一管理在一个 &lt;code>reference.bib&lt;/code> 文件里，但是发现 &lt;code>org-ref&lt;/code> 对 &lt;code>ox-hugo&lt;/code> 似乎不太支持，因此使用 &lt;code>citeproc-org&lt;/code> 进行简单的配置即可正常到处参考文献，如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-emacs-lisp" data-lang="emacs-lisp">&lt;span class="p">(&lt;/span>&lt;span class="nv">citeproc-org-setup&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="c1">;; 可以将其写入配置文件中，或执行&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在相应位置中插入参考文献，调用 &lt;code>M-x org-ref-helm-insert-cite-link&lt;/code> 即可，导出文章即可以看到参考文献成功导出。&lt;/p>
&lt;h2 id="参考">参考&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://zhuanlan.zhihu.com/p/54705090">Emacs Org-mode学术写作&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.xianmin.org/post/ox-hugo/">博客写作流程之工具篇： emacs, orgmode, hugo &amp;amp; ox-hugo&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://q3yi.me/post/build-blog-with-orgmode-hugo-and-github-pages/">使用orgmode+hugo+github pages搭建博客&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://zlearning.netlify.app/linux/emacs/emacs-hugo-academic.html">使用Emacs和Hugo academic主题&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>使用 Hugo 搭建个人网站（博客、个人主页）并发布到 Github 上</title><link>https://kinredon.github.io/post/how-to-publish-personal-website-on-github/</link><pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/how-to-publish-personal-website-on-github/</guid><description>&lt;h2 id="前言">前言&lt;/h2>
&lt;p>相信很多人都有搭建个人网站的需求，可能是想写自己的博文，传达一些思想给社区。也有可能你是一名科研工作者，需要搭建个人学术主页展示科研成果。我也或多或少出于以上原因，选择搭建了个人网站，搭建过程中出现了许多问题，因此记录和分享，避免下次踩坑。Anyway，本文记录使用搭建个人博客的全过程，包括网站工具 &lt;a href="https://gohugo.io/">Hugo&lt;/a> 的介绍和使用设置，以及如何将个人网站发布在免费托管平台，也就是 GitHub Pages 上。&lt;/p>
&lt;p>我选择 Hugo 的原因主要有三点：&lt;/p>
&lt;ul>
&lt;li>简单易用；&lt;/li>
&lt;li>&lt;a href="https://gohugo.io/">Hugo&lt;/a> 能够快速地构建个人网站；&lt;/li>
&lt;li>拥有丰富的主题，可供挑选 &lt;a href="https://jamstackthemes.dev/ssg/hugo/">Hugo Themes&lt;/a>；&lt;/li>
&lt;/ul>
&lt;p>选择 GitHub Pages 的原因就更简单了，免费又好用。&lt;/p>
&lt;h2 id="hugo-的安装和使用">Hugo 的安装和使用&lt;/h2>
&lt;p>Hugo 宣传号称是世界上最快构建网站的框架，也是最流行的静态网站生成工具之一。&lt;/p>
&lt;h3 id="安装-hugo">安装 Hugo&lt;/h3>
&lt;p>由于我的操作系统是 MacOs 因此安装起来特别简单：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">brew install hugo
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>其他平台可参考 &lt;a href="https://gohugo.io/getting-started/installing">Hugo Install&lt;/a>。&lt;/p>
&lt;h3 id="创建个人网站">创建个人网站&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hugo new site quickstart
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="使用-hugo-主题">使用 Hugo 主题&lt;/h3>
&lt;p>我使用的是 &lt;a href="https://github.com/xianmin/hugo-theme-jane">jane&lt;/a>, 将主题 &lt;code>clone&lt;/code> 到 &lt;code>theme&lt;/code> 目录下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">cd&lt;/span> quickstart
git clone https://github.com/xianmin/hugo-theme-jane.git --depth&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span> themes/jane
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用示例文本和默认的站点设置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">cp -r themes/jane/exampleSite/content ./
cp themes/jane/exampleSite/config.toml ./
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>启动 Hugo 服务器，在 &lt;a href="http://localhost:1313/">http://localhost:1313/&lt;/a> 将会看到示例 jane 主题的示例网站：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">hugo server
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="个人配置和网站生成">个人配置和网站生成&lt;/h3>
&lt;p>配置文件在网站根目录 &lt;code>quickstart&lt;/code> 下 &lt;code>config.toml&lt;/code> , 根据自身需求进行修改。在 jane 主题下的 &lt;code>exampleSite&lt;/code> 文件夹中的文件可作为参考。默认的文章将存储在 &lt;code>./content/post&lt;/code> 中，每当写完文章，运行 &lt;code>hugo&lt;/code> 命令，Hugo 将自动生成静态网站到 &lt;code>public&lt;/code> 文件夹中，我们只需要将该文件夹的内容发布在网络上即可。&lt;/p>
&lt;p>更多关于主题的配置可以参考 &lt;a href="https://github.com/xianmin/hugo-theme-jane/blob/master/README-zh.md">jane README.md&lt;/a>。&lt;/p>
&lt;h2 id="github-pages">GitHub Pages&lt;/h2>
&lt;p>我个人经常使用 GitHub，也见到很多大佬利用 GitHub pages 挂载自己的个人网站，发现配置起来也很简单，因此选择使用 GitHub pages 来进行配置，关于 GitHub pages 可以查看&lt;a href="https://pages.github.com/">官网&lt;/a>，主要包括四个步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>创建一个与 &lt;code>username&lt;/code> 同名的 &lt;strong>空&lt;/strong> &lt;code>username.github.io&lt;/code> 仓库，不包含任何内容，如 &lt;code>readme.md=，比如我的用户名为 =kinredon&lt;/code>, 因此我创建了一个仓库，名为 &lt;code>kinredon.github.io&lt;/code>;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>克隆仓库到本地&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">git clone https://github.com/kinredon/kinredon.github.io
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>添加个人网站内容到该仓库&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="c1"># copy 生成的网站内容到仓库文件夹下&lt;/span>
cp -rf quickstart/public/* kinredon.github.io/
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>将文件内容同步更新到 GitHub 服务器上&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">cd&lt;/span> kinredon.github.io
git add .
git commit -m &lt;span class="s2">&amp;#34;init the website&amp;#34;&lt;/span>
git push
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>此时，通过进入 &lt;a href="https://kinredon.github.io">https://kinredon.github.io&lt;/a> 即可访问自己的个人网站。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>上面的步骤略显麻烦，每次需要将生成在 &lt;code>public&lt;/code> 文件夹下的目录拷贝到 &lt;code>kinredon.github.io&lt;/code> 目录下，然后发布到远程服务器。根据 &lt;a href="https://gohugo.io/hosting-and-deployment/hosting-on-github/">Host on GitHub&lt;/a>，发布到 GitHub Pages 有两种方式, 一种是直接使用仓库目录下的 &lt;code>doc&lt;/code> 目录作为原本 &lt;code>public&lt;/code> 目录，详情可以参考 &lt;a href="https://patrolli.github.io/xssq/post/hugo%5F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">hugo 博客搭建&lt;/a>。我采用的方式是利用 GitHub Action 自动完成上述过程。&lt;/p>
&lt;h3 id="使用-github-action-自动发布文章">使用 GitHub Action 自动发布文章&lt;/h3>
&lt;p>这里主要参考 &lt;a href="https://vinurs.me/posts/1a329bf3-fbb7-4006-9714-d3b072826376/">搭建个人blog&lt;/a>, 使用 &lt;code>master&lt;/code> 分支发布文章，使用一个新的 &lt;code>source&lt;/code> 分支进行写作，写作完成后上传 &lt;code>source&lt;/code> ，GitHub Action 自动将 &lt;code>source&lt;/code> 分支的 &lt;code>publish&lt;/code> 文件夹拷贝到 &lt;code>master&lt;/code> 分支，从而完成文章的发布。&lt;/p>
&lt;p>主要步骤如下：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>在 GitHub 上的个人网站仓库 &lt;code>kinredon.github.io&lt;/code> 新建 &lt;code>source&lt;/code> 分支&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211004154805.png" alt="Figure 1: 创建 source 分支，由于我已经创建过，所以这里以 source-1 为例"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211004154805.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 1: 创建 source 分支，由于我已经创建过，所以这里以 source-1 为例&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;/li>
&lt;li>
&lt;p>清除文件夹 &lt;code>kinredon.github.io&lt;/code> 中的内容，并将个人网站 &lt;code>quickstart&lt;/code> 中的所有内容 copy 到 &lt;code>kinredon.github.io&lt;/code> ：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">git clone --branch&lt;span class="o">=&lt;/span>&lt;span class="nb">source&lt;/span> https://github.com/kinredon/kinredon.github.io.git
rm -rf kinredon.github.io/*
cp -rf quickstart/* kinredon.github.io
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>生成 &lt;code>ACTIONS_DEPLOY_KEY&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">ssh-keygen -t rsa -b &lt;span class="m">4096&lt;/span> -C &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>git config user.email&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> -f gh-pages -N &lt;span class="s2">&amp;#34;&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>将生成的私钥文件 &lt;code>gh-pages&lt;/code> (注意不是公钥 &lt;code>gh-pages.pub&lt;/code>) 中的内容复制填写到 GitHub 仓库设置中，即在 &lt;code>kinredon.github.io&lt;/code> 项目主页中，找到 Repository Settings -&amp;gt; Secrets -&amp;gt; 添加这个私钥的内容并命名为 &lt;code>ACTIONS_DEPLOY_KEY&lt;/code> 。
然后在 &lt;code>kinredon.github.io&lt;/code> 项目主页中，找到 Repository Settings -&amp;gt; Deploy Keys -&amp;gt; 添加这个公钥的内容，命名为 &lt;code>ACTIONS_DEPLOY_KEY&lt;/code> ，并勾选 Allow write access。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>配置 workflow&lt;/p>
&lt;p>创建 workflow 文件&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">mkdir -p .github/workflows/
touch .github/workflows/main.yml
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 &lt;code>main.yaml&lt;/code> 中撰写 workflow，内容如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">name: github pages
on:
push:
branches:
​ - &lt;span class="nb">source&lt;/span>
jobs:
build-deploy:
runs-on: ubuntu-18.04
steps:
​ - uses: actions/checkout@master
​ - name: Checkout submodules
shell: bash
run: &lt;span class="p">|&lt;/span>
&lt;span class="nv">auth_header&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>git config --local --get http.https://github.com/.extraheader&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
git submodule sync --recursive
git -c &lt;span class="s2">&amp;#34;http.extraheader=&lt;/span>&lt;span class="nv">$auth_header&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> -c protocol.version&lt;span class="o">=&lt;/span>&lt;span class="m">2&lt;/span> submodule update --init --force --recursive --depth&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span>
- name: Setup Hugo
uses: peaceiris/actions-hugo@v2
with:
hugo-version: &lt;span class="s1">&amp;#39;latest&amp;#39;&lt;/span>
extended: &lt;span class="nb">true&lt;/span>
- name: Build
run: hugo --gc --minify --cleanDestinationDir
- name: Deploy
uses: peaceiris/actions-gh-pages@v3
with:
deploy_key: &lt;span class="si">${&lt;/span>&lt;span class="p">{ secrets.ACTIONS_DEPLOY_KEY &lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="o">}&lt;/span>
publish_dir: ./public
publish_branch: main
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>注意，如果你的仓库是 &lt;code>master&lt;/code> 分支作为主分支，将 &lt;code>publish_branch&lt;/code> 后面的 &lt;code>main&lt;/code> 修改为 &lt;code>master&lt;/code> ;&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将 source 分支发送到远程&lt;/p>
&lt;p>发送脚本 &lt;code>deploy.sh&lt;/code> :&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;span class="cp">&lt;/span>git add .
git commit -m &lt;span class="s2">&amp;#34;update article&amp;#34;&lt;/span>
git push
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>推送到远程分支：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">sh deploy.sh
&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>推送成功后，可以在项目主页中的 action 里面查看自动部署是否成功，即 &lt;a href="https://github.com/kinredon/kinredon.github.io/actions">https://github.com/kinredon/kinredon.github.io/actions&lt;/a>；&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>半监督目标检测（Semi-Supervised Object Detection，SSOD）相关方法介绍</title><link>https://kinredon.github.io/post/semi-supervised-object-detection/</link><pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate><guid>https://kinredon.github.io/post/semi-supervised-object-detection/</guid><description>&lt;p>近期阅读了一些半监督目标检测（Semi-Supervised Object Detection，SSOD）的文章，特此总结，以供未来查阅。&lt;/p>
&lt;h2 id="什么是半监督目标检测">什么是半监督目标检测？&lt;/h2>
&lt;p>传统机器学习根据训练数据集中的标注情况，有着不同的场景，主要包括：监督学习、弱监督学习、弱半监督学习、半监督学习。由于目标检测任务的特殊性，在介绍半监督目标检测方法之前，我们查看一下目标检测在这四个方向下的具体设定，如下图所示（不包括无监督学习）：&lt;/p>
&lt;link rel="stylesheet" href="https://kinredon.github.io/css/hugo-easy-gallery.css" />
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205549.png" alt="Figure 1: 图一 目标检测的不同的 setting"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205549.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 1: 图一 目标检测的不同的 setting&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>总而言之，我们可以讲目标检测的 setting 分为四个部分：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>有监督目标检测&lt;/strong> ：拥有大规模带标签的数据，包括完整的实例级别的标注，即包含坐标和类别信息；&lt;/li>
&lt;li>&lt;strong>弱监督目标检测&lt;/strong> ：数据集中的标注仅包含类别信息，不包含坐标信息，如图一 b 所示；&lt;/li>
&lt;li>&lt;strong>弱半监督目标检测&lt;/strong> ：数据集中拥有部分实例级别的标注，大量弱标注数据，模型希望利用大规模的弱标注数据提升模型的检测能力；&lt;/li>
&lt;li>&lt;strong>半监督目标检测&lt;/strong> ：数据集中拥有部分实例级别的标注，大量未标注数据，模型希望利用大规模的无标注的数据提升模型的检测能力；&lt;/li>
&lt;/ul>
&lt;p>半监督目标检测方法的核心在于，如何充分利用大量未标注、多样性的数据提升模型在测试集上的性能，目前的半监督目标检测方法主要有两个方向：&lt;/p>
&lt;ol>
&lt;li>一致性学习（Consistency based Learning）&lt;/li>
&lt;li>伪标签（Pseudo-label based Learning）&lt;/li>
&lt;/ol>
&lt;p>前者利用两个深度卷积神经网络学习同一张 unlabeled 图像不同扰动（比如水平翻转，不同的对比度，亮度等）之间的一致性，充分利用 unlabeled data的信息。后者利用在 labeled data 上学习的预训练模型对 unlabeled data 进行推理，经过 NMS 后减少大量冗余框后，利用一个阈值去挑选伪标签，最后利用伪标签训练模型。个人认为这两种方法没有本质的区别，本身都是伪标签技术，一致性学习可以认为是一种 soft pseudo label，而后者是一种 hard pseudo label。&lt;/p>
&lt;p>接下来我讲介绍几篇近期半监督目标检测文章，主要发表在 ICLR, NeurIPS, CVPR等会议。&lt;/p>
&lt;h2 id="consistency-based-semi-supervised-learning-for-object-detection-neurips-19">Consistency-based Semi-supervised Learning for Object Detection, NeurIPS 19&lt;/h2>
&lt;p>CSD 这篇文章是比较早期的半监督目标检测方法，非常简单，该文章提出了一个 Consistency-based 半监督目标检测算法，可以同时在单阶段和双阶段检测器上工作。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205728.png" alt="Figure 2: 图二 CSD 半监督目标检测算法结构图"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205728.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 2: 图二 CSD 半监督目标检测算法结构图&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>CSD 的结构如图二所示，以单阶段目标检测器为例，训练的损失函数主要包括两个部分，labeled sample 的监督损失和 unlabeled samples 的 Consistency loss。针对 unlabeled samples，首先将图像水平翻转，然后分别送入网络当中，得到对应的 Feature map，由于两张翻转的图像的空间位置是可以一一对应的，因此可以在对应的位置计算一致性损失。分类部分，利用 JS 散度作为 consistency loss；定位部分，利用 L2 loss 作为 consistency loss。&lt;/p>
&lt;p>双阶段检测器的部分与单阶段检测器类似，差别主要在于 RPN（Region Proposal Network） 对于不同的输入可能产生不同的 proposals，因此在计算 consistency loss 时无法一一对应。解决此问题也很简单，两张图像使用同一个 RPN 生成同一组 RoI (Region of Interest) 来提取特征得到 proposals。&lt;/p>
&lt;p>作者还提出了一个 Background elimination 方法来消除大量背景部分的损失主导训练过程的问题，因此作者定义了一个 mask 来过滤大量的背景样本：
\[
m^{k}=\left\{\begin{array}{ll}1, &amp;amp; \text { if } \operatorname{argmax}\left(f_{c l s}^{k}(I)\right) \neq b a c k g r o u n d \ 0, &amp;amp; \text { otherwise }\end{array}\right.
\]
其中，当该实例的类别不等于背景类时等于1，否则为 0。&lt;/p>
&lt;h2 id="a-simple-semi-supervised-learning-framework-for-object-detection">A Simple Semi-Supervised Learning Framework for Object Detection&lt;/h2>
&lt;p>STAC 提出了一个基于 hard pseudo label 的半监督目标检测算法，如图三所示，该方法包含四个步骤：&lt;/p>
&lt;ol>
&lt;li>首先利用 labeled data 训练一个 Teacher 模型；&lt;/li>
&lt;li>生成 pseudo label, 将 unlabeled data 输入进 Teacher 网络中，得到大量的目标框预测结果，利用 NMS 消除大量的冗余框，最后使用阈值来挑选高置信度的 pseudo label；&lt;/li>
&lt;li>应用 strong data augmentation。得到 pseudo label 后与 unlabeled image 图像相结合，包括图像级别的颜色抖动、geometric transformation(平移、旋转、剪切)、box-level transformation（小幅度的平移、旋转、剪切）；&lt;/li>
&lt;li>计算无监督 loss （pseudo label）和监督学习 loss；&lt;/li>
&lt;/ol>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205743.png" alt="Figure 3: 图三 STAC 半监督目标检测算法示意图"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205743.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 3: 图三 STAC 半监督目标检测算法示意图&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;h2 id="instant-teaching-an-end-to-end-semi-supervised-object-detection-framework">Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework&lt;/h2>
&lt;p>Instant-Teaching 主要的 motivation 在于 STAC 仅生成一次的 pseudo label，即离线生成，在训练的过程中不会更新。这样的模式存在一个问题是，当训练的模型精度逐步提升，超过原本的模型，继续使用原来模型生成的 pseudo label 会限制模型精度进一步提升。因此作者提出 Instant-Teaching，以及 Instant-Teaching*。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205807.png" alt="Figure 4: 图四 Instant-Teaching 和 Instant-Teaching\* 示意图"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205807.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 4: 图四 Instant-Teaching 和 Instant-Teaching\* 示意图&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>Instant-Teaching 采用即时生成 pseudo label 的模式，在每一个迭代中，包括两个步骤：&lt;/p>
&lt;ol>
&lt;li>生成 pseudo label: 对 unlabeled image 进行 weak augmentation，送入模型中得到 hard label；&lt;/li>
&lt;li>利用生成的 pseudo label 进行 strong augmentation，除了 在 STAC 中的数据增强，还包括了 Mixup 和 Mosaic，利用增强后的数据训练模型；&lt;/li>
&lt;/ol>
&lt;p>Instant-Teaching 主要提出了一个 co-rectify scheme 来解决 pseudo label 的 confirmation bias 的问题（噪声 pseudo label 的错误累计效应）。因此，作者利用两个模型，给予不同的初始化参数，输入不同的数据增强的样本，分别彼此纠正和检测对方生成的 pseudo label，形式如图四右半部分。&lt;/p>
&lt;h2 id="data-uncertainty-guided-multi-phase-learning-for-semi-supervised-object-detection">Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection&lt;/h2>
&lt;p>这篇工作提出一个多阶段的学习半监督目标检测学习算法,前面的方法基本在伪标签生成后，直接拟合生成的伪标签，这样将会引发 label noise overfitting 问题，即由于深度网络较强的拟合能力，即时错误的标签模型也能够拟合。因此作者利用图像级别 uncertainty 来进行多阶段学习，思想类似于课程学习（curriculum learning），先学习 easy 样本再学习 difficult data。具体来说，作者利用 RPN 出来的 proposal 的平均分数作为 uncertainty 的指标。平均分数越高，uncertainty 越小，视为 easy sample，反之为 difficult sample。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205821.png" alt="Figure 5: 图五 DUGMPL示意图"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205821.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 5: 图五 DUGMPL示意图&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>在区域级别，作者提出 RoI 的 re-weighting 操作，作者从 Soft sampling for robust object detection 得到启示，对于具有噪声的数据（伪标签），在训练时，不同的 RoI 应该给予不同的权重，作者提出了几个的简单但有效的策略来解决这个问题，受限于篇幅，这里不再具体介绍，感兴趣可以去阅读原文的 Section 3.3.2.&lt;/p>
&lt;h2 id="unbiased-teacher-for-semi-supervised-object-detection">Unbiased Teacher for Semi-Supervised Object Detection&lt;/h2>
&lt;p>这篇文章发表在 ICLR 2021， 主要思想还是说现在的半监督目标检测算法生成的标签具有 bias，这里作者主要 argue 的点在于目标检测中存在天然的类别不平衡问题，包括 RPN 前景和背景的分类，ROIHead 的多类别分类，因此作者提出了一个 Unbiased Teacher 方法，来解决此问题。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205832.png" alt="Figure 6: 图六 Unbiased Teacher 示意图"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205832.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 6: 图六 Unbiased Teacher 示意图&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>从方法上来说，非常的简单，首先是 Burn-IN stage，即在 labeled data 上训练一个预训练模型，然后利用 Mean Teacher 的结构，Teacher 生成 Pseudo label 来同时监督 RPN 和 ROIHead。不同的点在于，作者只利用 pseudo label 更新 RPN 和 ROIHead 的 classification 分支，主要原因在于由 confidence score 生成的 pseudo label 与 bounding box 位置的质量关系不大。除此之外，作者将原本的 cross entropy loss 替换为 Focal loss 来解决 pseudo label bias 问题，即 class imbalance。&lt;/p>
&lt;h2 id="interactive-self-training-with-mean-teachers-for-semi-supervised-object-detection">Interactive Self-Training with Mean Teachers for Semi-supervised Object Detection&lt;/h2>
&lt;p>这篇文章揭示了之前利用 pseudo label 的方法忽略了*同一张图片在不同的迭代的检测结果之间的差异性*，而且不同的模型对同一张图像的检测结果也有差异。&lt;/p>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205846.png" alt="Figure 7: 图七 不同迭代的模型对同一张图像的预测结果(a)(b),不同 ROIHead 的检测结果"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205846.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 7: 图七 不同迭代的模型对同一张图像的预测结果(a)(b),不同 ROIHead 的检测结果&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>因此作者提出一个基于 Mean Teacher 的 Interactive form of self-training 的半监督目标检测算法：&lt;/p>
&lt;ol>
&lt;li>解决不同训练迭代检测结果的不稳定问题，作者使用 NMS 将不同迭代的检测结果进行融合。&lt;/li>
&lt;li>同时利用两个检测头部 ROIHead 生成 pseudo label，两个检测头部可以相互提供有用的互补信息。&lt;/li>
&lt;/ol>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205855.png" alt="Figure 8: 图八 Interactive Self-Training 的算法步骤"/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205855.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 8: 图八 Interactive Self-Training 的算法步骤&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;p>IST 算法的主要步骤如图八所示：&lt;/p>
&lt;ul>
&lt;li>使用 labeled data 训练一个拥有两个 ROIHead 的预训练模型;&lt;/li>
&lt;li>利用预训练模型生成两个对应的伪标签;&lt;/li>
&lt;li>利用 labeled data 和 unlabeled data 进行监督学习，图八中 Pseudo Labels Memory 用来使用 NMS 融合不同迭代的检测结果。该步骤详情如图九所示，利用 Mean Teacher 的结构，teacher 生成 pseudo label 并与 Memory 中的 pseudo label 进行融合，并更新 Memory。作者使用 Dropblock 模块确保不同的 ROIHead 能够独立收敛，并提供互补的信息，即图九中的 D。&lt;/li>
&lt;/ul>
&lt;div class="box">
&lt;figure itemprop="associatedMedia"
itemscope itemtype="http://schema.org/ImageObject" >
&lt;div class="img">
&lt;img itemprop="thumbnail" src="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205905.png" alt="Figure 9: 图九 Illustration of interactive self-training with mean teachers."/>
&lt;/div>
&lt;a href="https://kinredon.github.io/ox-hugo/pngpaste_clipboard_file_20211003205905.png" itemprop="contentUrl">&lt;/a>
&lt;figcaption>
&lt;p>Figure 9: 图九 Illustration of interactive self-training with mean teachers.&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;/div>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>本文介绍了一些半监督目标检测算法，即如何利用大量的 unlabeled data 提升模型的检测性能，当前主要的方法包含 consistency based 以及 pseudo label based 两类。consistency based 方法主要学习模型在 unlabeled data 上的一致性，pseudo label 则利用在 unlabeled data 上生成 pseudo label 进而监督模型训练，主要的方向即为如何生成高质量的伪标签以及模型如何对抗在 unlabeled data 上的 noise label。本文介绍了的半监督目标检测方法不多，关于方法的介绍较为笼统，如有谬误，烦请指正，其中细节，还需仔细阅读文章，欢迎讨论。&lt;/p></description></item></channel></rss>